# 🚀 End-to-End ETL Pipeline with Azure Databricks

Welcome to my data engineering project showcasing a complete, production-grade ETL pipeline using **Azure Databricks** and **Delta Live Tables**, built on the **Medallion Architecture**.

![Architecture Diagram](Documents/bricksproject.jpg)

## 📌 Overview

This project demonstrates how to build scalable, modular, and cloud-native data pipelines using modern tools and best practices. It covers everything from raw data ingestion to analytical reporting.

## 🧱 Architecture Highlights

- 🥉 **Bronze Layer**: Raw data ingestion using Spark Autoloader  
- 🥈 **Silver Layer**: Data transformation and enrichment with PySpark  
- 🥇 **Gold Layer**: Star schema design for analytics, powered by Delta Live Tables  
- 🔄 **ETL Orchestration**: Managed with Databricks Workflows  
- 🔐 **Security & Governance**: Enforced via Unity Catalog  
- 📊 **Reporting**: Data served to Power BI and Azure Synapse Analytics

## ⚙️ Technologies Used

| Tool/Service              | Role in Pipeline                              |
|--------------------------|-----------------------------------------------|
| **Azure Databricks**     | Unified platform for ETL, analytics, and ML   |
| **Azure Data Lake Gen2** | Scalable storage for raw and processed data   |
| **PySpark**              | Data transformation and enrichment            |
| **Delta Lake**           | ACID-compliant storage with versioning        |
| **Delta Live Tables**    | Declarative ETL pipelines with data quality   |
| **Unity Catalog**        | Data governance and reusable functions        |
| **Databricks Workflows** | Pipeline orchestration and scheduling         |
| **Power BI / Synapse**   | Reporting and data warehousing                |

## 🔧 Key Features

- ✅ Incremental data loading with Spark Streaming and Autoloader  
- 🧼 Complex data cleaning and enrichment using PySpark  
- 🧩 Modular, reusable code with Python OOP in PySpark  
- 🕰️ SCD Type 1 & Type 2 implementation for historical tracking  
- 📐 Star schema design for analytical querying  
- 🔄 End-to-end orchestration with Databricks Workflows  
- 🔍 Unity Catalog for governance and function reuse  
- 📊 Reporting integration with Power BI and Synapse



